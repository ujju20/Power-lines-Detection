{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for dirname, _, filenames in os.walk('/kaggle/input'):\\n    for filename in filenames:\\n        print(os.path.join(dirname, filename))\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "'''for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))'''\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for detecting Horizontal and Vertical edges in a image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel_1 is for detecting the vertical edges and kernel_2 is for detecting the horizontal edges and this detection makes the image more clear for detecting the power lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import convolve2d\n",
    "\n",
    "kernel_1 = np.array([[-1, 0, 1],\n",
    "                   [-1, 0, 1],\n",
    "                   [-1, 0, 1]])\n",
    "kernel_2 = np.array([[-1, -1, -1],\n",
    "                   [0, 0, 0],\n",
    "                   [1, 1, 1]])\n",
    "def edge(im):\n",
    "    out1 = convolve2d(im, kernel_1)\n",
    "    out2 = convolve2d(im, kernel_2)\n",
    "    new=np.sqrt(np.square(out1)+np.square(out2))\n",
    "    return new\n",
    "\n",
    "def make(im):\n",
    "    im= cv2.cvtColor(im,cv2.COLOR_RGB2GRAY)\n",
    "    a=edge(im)\n",
    "    a=a[:128,:128]\n",
    "    im1=im.reshape(128,128,1)\n",
    "    im2=a.reshape(128,128,1)\n",
    "    return np.concatenate((im1,im2), axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import os \n",
    "import glob \n",
    "img_dir = \"/kaggle/input/recognizance-2/Data/train/Powerline\" # Enter Directory of all images  \n",
    "data_path = os.path.join(img_dir,'*.bmp') \n",
    "files = glob.glob(data_path) \n",
    "train = [] \n",
    "train_labels=[]\n",
    "for f1 in files: \n",
    "    img = cv2.imread(f1) \n",
    "    train.append(make(img))\n",
    "    train_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = \"/kaggle/input/recognizance-2/Data/train/No_powerline\" # Enter Directory of all images  \n",
    "data_path = os.path.join(img_dir,'*.bmp') \n",
    "files = glob.glob(data_path) \n",
    "for f1 in files: \n",
    "    img = cv2.imread(f1) \n",
    "    train.append(make(img))\n",
    "    train_labels.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffling the training images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "temp=list(zip(train,train_labels))\n",
    "for i in range(100):\n",
    "    random.shuffle(temp)\n",
    "train,train_labels=zip(*temp)\n",
    "train=np.array(train)\n",
    "train_labels=np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=np.array(train)\n",
    "train_labels=np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 128, 128, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "sns.set(style='white', context='notebook', palette='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 16, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (128,128,2)))\n",
    "model.add(Conv2D(filters = 16, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer =  RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer = optimizer , loss = \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30 # Turn epochs to 30 to get 0.9967 accuracy\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(train, train_labels, test_size = 0.1, random_state= 2)\n",
    "X_train=X_train/255.0\n",
    "X_val=X_val/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train/255.0\n",
    "Y_train=train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - 10s 54ms/step - loss: 0.7049 - accuracy: 0.5219\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 6s 55ms/step - loss: 0.6128 - accuracy: 0.6660\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 5s 54ms/step - loss: 0.4672 - accuracy: 0.7662\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 5s 54ms/step - loss: 0.3796 - accuracy: 0.8201\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 5s 54ms/step - loss: 0.3763 - accuracy: 0.8305\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 5s 54ms/step - loss: 0.3404 - accuracy: 0.8559\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 5s 54ms/step - loss: 0.3178 - accuracy: 0.8700\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 6s 56ms/step - loss: 0.3006 - accuracy: 0.8695\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 5s 54ms/step - loss: 0.2875 - accuracy: 0.8870\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 5s 54ms/step - loss: 0.2740 - accuracy: 0.8894\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 5s 54ms/step - loss: 0.2617 - accuracy: 0.8967\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 5s 54ms/step - loss: 0.2615 - accuracy: 0.8900\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 5s 55ms/step - loss: 0.2378 - accuracy: 0.9055\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 6s 56ms/step - loss: 0.2286 - accuracy: 0.9164\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 5s 55ms/step - loss: 0.2208 - accuracy: 0.9156\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 5s 54ms/step - loss: 0.2186 - accuracy: 0.9202\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 5s 54ms/step - loss: 0.2078 - accuracy: 0.9243\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 5s 55ms/step - loss: 0.2057 - accuracy: 0.9191\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 5s 54ms/step - loss: 0.2123 - accuracy: 0.9250\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 6s 56ms/step - loss: 0.2017 - accuracy: 0.9298\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 5s 54ms/step - loss: 0.1927 - accuracy: 0.9313\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 5s 54ms/step - loss: 0.1914 - accuracy: 0.9355\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 5s 54ms/step - loss: 0.1858 - accuracy: 0.9327\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 5s 55ms/step - loss: 0.1767 - accuracy: 0.9404\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 5s 54ms/step - loss: 0.1924 - accuracy: 0.9378\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 6s 56ms/step - loss: 0.1614 - accuracy: 0.9431\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 5s 54ms/step - loss: 0.1565 - accuracy: 0.9460\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 5s 55ms/step - loss: 0.1684 - accuracy: 0.9429\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 5s 54ms/step - loss: 0.1682 - accuracy: 0.9397\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 5s 54ms/step - loss: 0.1634 - accuracy: 0.9461\n"
     ]
    }
   ],
   "source": [
    "history = model.fit( X_train,Y_train, batch_size=batch_size,\n",
    "                              epochs = 30, \n",
    "                              verbose = 1, steps_per_epoch=X_train.shape[0] // batch_size\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = \"/kaggle/input/recognizance-2/Data/test\" # Enter Directory of all images  \n",
    "data_path = os.path.join(img_dir,'*.bmp') \n",
    "files = glob.glob(data_path) \n",
    "test_images = []\n",
    "for f1 in files: \n",
    "    img = cv2.imread(f1) \n",
    "    test_images.append(make(img)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images=np.array(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images=test_images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6078, 128, 128, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels=model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[]\n",
    "for i in test_labels:\n",
    "    if(i>0.5):\n",
    "        labels.append(\"YES\")\n",
    "    else:\n",
    "        labels.append(\"NO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_names=[]\n",
    "for f1 in files:  \n",
    "    test_names.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Check   (3311).bmp'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(0,len(test_images)):\n",
    "    test_names[i]=test_names[i][39:]\n",
    "test_names[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image file name</th>\n",
       "      <th>Powerline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Check   (3311).bmp</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Check  (2007).bmp</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Check  (118).bmp</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Check   (340).bmp</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Check  (2374).bmp</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6073</th>\n",
       "      <td>Check   (633).bmp</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6074</th>\n",
       "      <td>Check   (1595).bmp</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6075</th>\n",
       "      <td>Check   (2571).bmp</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6076</th>\n",
       "      <td>Check  (2029).bmp</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6077</th>\n",
       "      <td>Check   (516).bmp</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6078 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         image file name Powerline\n",
       "0     Check   (3311).bmp        NO\n",
       "1      Check  (2007).bmp       YES\n",
       "2       Check  (118).bmp       YES\n",
       "3      Check   (340).bmp        NO\n",
       "4      Check  (2374).bmp       YES\n",
       "...                  ...       ...\n",
       "6073   Check   (633).bmp        NO\n",
       "6074  Check   (1595).bmp        NO\n",
       "6075  Check   (2571).bmp        NO\n",
       "6076   Check  (2029).bmp       YES\n",
       "6077   Check   (516).bmp        NO\n",
       "\n",
       "[6078 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file=pd.DataFrame(test_names,columns=['image file name'])\n",
    "file['Powerline']=labels\n",
    "file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the file for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.to_csv('output.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
